{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure OpenAI Service - Q&A with semantic answering Quickstart app\n",
    "\n",
    "This notebook helps you to build a simple Q&A demo application by doing the following steps\n",
    "\n",
    "1. Data preparation - you will need to adapt this code to have it work with your data\n",
    "1. Embedding creation - this will mostly work out of the box\n",
    "1. Prompt creation - this will mostly work out of the box, but you could adapt this a little bit\n",
    "1. App creation - this will mostly work out of the box, but you can make changes if needed\n",
    "\n",
    "Firstly, create a file called `.env` in this folder, and add the following content, obviously with your values:\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=xxxxxx\n",
    "OPENAI_API_BASE=https://xxxxxxx.openai.azure.com/\n",
    "```\n",
    "\n",
    "Then, let's install all dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: streamlit in /home/vscode/.local/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (1.27.0)\n",
      "Requirement already satisfied: openai in /home/vscode/.local/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (0.27.1)\n",
      "Requirement already satisfied: python-dotenv in /home/vscode/.local/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (0.21.0)\n",
      "Requirement already satisfied: numpy in /home/vscode/.local/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (1.24.3)\n",
      "Requirement already satisfied: pandas in /home/vscode/.local/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (2.1.1)\n",
      "Requirement already satisfied: matplotlib in /home/vscode/.local/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (3.6.3)\n",
      "Requirement already satisfied: plotly in /home/vscode/.local/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (5.12.0)\n",
      "Requirement already satisfied: scipy in /home/vscode/.local/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (1.10.0)\n",
      "Requirement already satisfied: scikit-learn in /home/vscode/.local/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (1.2.0)\n",
      "Requirement already satisfied: tenacity in /home/vscode/.local/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (8.2.3)\n",
      "Requirement already satisfied: tiktoken in /home/vscode/.local/lib/python3.9/site-packages (from -r requirements.txt (line 11)) (0.3.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /home/vscode/.local/lib/python3.9/site-packages (from streamlit->-r requirements.txt (line 1)) (5.1.1)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /home/vscode/.local/lib/python3.9/site-packages (from streamlit->-r requirements.txt (line 1)) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /home/vscode/.local/lib/python3.9/site-packages (from streamlit->-r requirements.txt (line 1)) (5.3.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /home/vscode/.local/lib/python3.9/site-packages (from streamlit->-r requirements.txt (line 1)) (8.1.7)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in /home/vscode/.local/lib/python3.9/site-packages (from streamlit->-r requirements.txt (line 1)) (6.8.0)\n",
      "Requirement already satisfied: packaging<24,>=16.8 in /home/vscode/.local/lib/python3.9/site-packages (from streamlit->-r requirements.txt (line 1)) (23.1)\n",
      "Requirement already satisfied: pillow<10,>=7.1.0 in /home/vscode/.local/lib/python3.9/site-packages (from streamlit->-r requirements.txt (line 1)) (9.5.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /home/vscode/.local/lib/python3.9/site-packages (from streamlit->-r requirements.txt (line 1)) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=6.0 in /home/vscode/.local/lib/python3.9/site-packages (from streamlit->-r requirements.txt (line 1)) (13.0.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /home/vscode/.local/lib/python3.9/site-packages (from streamlit->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.18 in /home/vscode/.local/lib/python3.9/site-packages (from streamlit->-r requirements.txt (line 1)) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /home/vscode/.local/lib/python3.9/site-packages (from streamlit->-r requirements.txt (line 1)) (13.5.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /home/vscode/.local/lib/python3.9/site-packages (from streamlit->-r requirements.txt (line 1)) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.1.0 in /home/vscode/.local/lib/python3.9/site-packages (from streamlit->-r requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: tzlocal<6,>=1.1 in /home/vscode/.local/lib/python3.9/site-packages (from streamlit->-r requirements.txt (line 1)) (5.0.1)\n",
      "Requirement already satisfied: validators<1,>=0.2 in /home/vscode/.local/lib/python3.9/site-packages (from streamlit->-r requirements.txt (line 1)) (0.22.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /home/vscode/.local/lib/python3.9/site-packages (from streamlit->-r requirements.txt (line 1)) (3.1.36)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /home/vscode/.local/lib/python3.9/site-packages (from streamlit->-r requirements.txt (line 1)) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /home/vscode/.local/lib/python3.9/site-packages (from streamlit->-r requirements.txt (line 1)) (6.3.3)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in /home/vscode/.local/lib/python3.9/site-packages (from streamlit->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: tqdm in /home/vscode/.local/lib/python3.9/site-packages (from openai->-r requirements.txt (line 2)) (4.66.1)\n",
      "Requirement already satisfied: aiohttp in /home/vscode/.local/lib/python3.9/site-packages (from openai->-r requirements.txt (line 2)) (3.8.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vscode/.local/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 5)) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/vscode/.local/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 5)) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/vscode/.local/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/vscode/.local/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/vscode/.local/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 6)) (4.42.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/vscode/.local/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 6)) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/vscode/.local/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 6)) (3.1.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/vscode/.local/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 9)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/vscode/.local/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 9)) (3.2.0)\n",
      "Requirement already satisfied: blobfile>=2 in /home/vscode/.local/lib/python3.9/site-packages (from tiktoken->-r requirements.txt (line 11)) (2.0.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/vscode/.local/lib/python3.9/site-packages (from tiktoken->-r requirements.txt (line 11)) (2023.8.8)\n",
      "Requirement already satisfied: jinja2 in /home/vscode/.local/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/vscode/.local/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 1)) (4.19.1)\n",
      "Requirement already satisfied: toolz in /home/vscode/.local/lib/python3.9/site-packages (from altair<6,>=4.0->streamlit->-r requirements.txt (line 1)) (0.12.0)\n",
      "Requirement already satisfied: pycryptodomex~=3.8 in /home/vscode/.local/lib/python3.9/site-packages (from blobfile>=2->tiktoken->-r requirements.txt (line 11)) (3.19.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.25.3 in /home/vscode/.local/lib/python3.9/site-packages (from blobfile>=2->tiktoken->-r requirements.txt (line 11)) (1.26.16)\n",
      "Requirement already satisfied: lxml~=4.9 in /home/vscode/.local/lib/python3.9/site-packages (from blobfile>=2->tiktoken->-r requirements.txt (line 11)) (4.9.3)\n",
      "Requirement already satisfied: filelock~=3.0 in /home/vscode/.local/lib/python3.9/site-packages (from blobfile>=2->tiktoken->-r requirements.txt (line 11)) (3.12.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/vscode/.local/lib/python3.9/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 1)) (4.0.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/vscode/.local/lib/python3.9/site-packages (from importlib-metadata<7,>=1.4->streamlit->-r requirements.txt (line 1)) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.9/site-packages (from python-dateutil<3,>=2.7.3->streamlit->-r requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vscode/.local/lib/python3.9/site-packages (from requests<3,>=2.18->streamlit->-r requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vscode/.local/lib/python3.9/site-packages (from requests<3,>=2.18->streamlit->-r requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vscode/.local/lib/python3.9/site-packages (from requests<3,>=2.18->streamlit->-r requirements.txt (line 1)) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/vscode/.local/lib/python3.9/site-packages (from rich<14,>=10.14.0->streamlit->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/vscode/.local/lib/python3.9/site-packages (from rich<14,>=10.14.0->streamlit->-r requirements.txt (line 1)) (2.16.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vscode/.local/lib/python3.9/site-packages (from aiohttp->openai->-r requirements.txt (line 2)) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vscode/.local/lib/python3.9/site-packages (from aiohttp->openai->-r requirements.txt (line 2)) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/vscode/.local/lib/python3.9/site-packages (from aiohttp->openai->-r requirements.txt (line 2)) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/vscode/.local/lib/python3.9/site-packages (from aiohttp->openai->-r requirements.txt (line 2)) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vscode/.local/lib/python3.9/site-packages (from aiohttp->openai->-r requirements.txt (line 2)) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vscode/.local/lib/python3.9/site-packages (from aiohttp->openai->-r requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/vscode/.local/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit->-r requirements.txt (line 1)) (5.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vscode/.local/lib/python3.9/site-packages (from jinja2->altair<6,>=4.0->streamlit->-r requirements.txt (line 1)) (2.1.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/vscode/.local/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 1)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/vscode/.local/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 1)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/vscode/.local/lib/python3.9/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->-r requirements.txt (line 1)) (0.10.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/vscode/.local/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->-r requirements.txt (line 1)) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBEDDING_MODEL gpt-35-turbo-16k\n",
      "EMBEDDING_ENCODING cl100k_base\n",
      "EMBEDDING_CHUNK_SIZE 8000\n",
      "COMPLETION_MODEL gpt-35-turbo\n",
      "OPENAI_OPENAI_API_API_VERSION 2022-12-01\n",
      "OPENAI_API_BASE https://neuronvisionws1.openai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import tiktoken\n",
    "import openai\n",
    "import numpy as np\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "from openai.embeddings_utils import cosine_similarity\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# Configure Azure OpenAI Service API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = os.getenv('OPENAI_OPENAI_API_API_VERSION', \"2022-12-01\")\n",
    "OPENAI_API_BASE=openai.api_base = os.getenv('OPENAI_API_BASE')\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Define embedding model and encoding\n",
    "EMBEDDING_MODEL = os.getenv('OPENAI_EMBEDDING_MODEL', 'text-embedding-ada-002')\n",
    "EMBEDDING_ENCODING = os.getenv('OPENAI_EMBEDDING_ENCODING', 'cl100k_base')\n",
    "EMBEDDING_CHUNK_SIZE = os.getenv('OPENAI_EMBEDDING_CHUNK_SIZE',)\n",
    "COMPLETION_MODEL = os.getenv('OPENAI_COMPLETION_MODEL', 'text-davinci-003')\n",
    "\n",
    "# initialize tiktoken for encoding text\n",
    "encoding = tiktoken.get_encoding(EMBEDDING_ENCODING)\n",
    "\n",
    "params_gathered = dict(\n",
    "    EMBEDDING_MODEL=EMBEDDING_MODEL,\n",
    "    EMBEDDING_ENCODING=EMBEDDING_ENCODING,\n",
    "    EMBEDDING_CHUNK_SIZE=EMBEDDING_CHUNK_SIZE,\n",
    "    COMPLETION_MODEL=COMPLETION_MODEL,\n",
    "    OPENAI_OPENAI_API_API_VERSION=openai.api_version ,\n",
    "    OPENAI_API_BASE=OPENAI_API_BASE\n",
    ")\n",
    "for key, val in params_gathered.items():\n",
    "    print(key, val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Adapt this code to read in our data, the output should be an Python array with dicts inside, containing the keys filename, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "Filename: overview_translator.txt Content: \n",
      "# What is Azure Cognitive Services Translator?\n",
      "\n",
      "Translator Service is a cloud-b... \n",
      "---> Tokens: 745\n",
      "\n",
      "Filename: overview_openai.txt Content: \n",
      "# What is Azure OpenAI?\n",
      "\n",
      "The Azure OpenAI service provides REST API access to O... \n",
      "---> Tokens: 1912\n",
      "\n",
      "Filename: overview_clu.txt Content: \n",
      "# What is conversational language understanding?\n",
      "\n",
      "Conversational language under... \n",
      "---> Tokens: 1344\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# list all files in the data\n",
    "data_dir = os.path.join(os.getcwd(), \"../data/qna/\")\n",
    "files = os.listdir(data_dir)\n",
    "\n",
    "# read content from each file and append it to documents\n",
    "documents = []\n",
    "for file in files:\n",
    "    with open(os.path.join(data_dir, file), \"r\") as f:\n",
    "        # read the content from the txt file\n",
    "        content = f.read()\n",
    "        documents.append({\n",
    "            \"filename\": file,\n",
    "            \"content\": content,\n",
    "        })\n",
    "\n",
    "# print some stats about the documents\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "for doc in documents:\n",
    "    num_tokens = len(encoding.encode(doc['content']))\n",
    "    print(f\"Filename: {doc['filename']} Content: {doc['content'][:80]}... \\n---> Tokens: {num_tokens}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the function to embed a single document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "The embeddings operation does not work with the specified model, gpt-35-turbo-16k. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/azure-openai-in-a-day-workshop/qna-quickstart-template/qna-app-quickstart.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bliterate-space-tribble-v97j7jj6q96cx9r5/workspaces/azure-openai-in-a-day-workshop/qna-quickstart-template/qna-app-quickstart.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m try_me  \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39membedd this text\u001b[39;49m\u001b[39m'\u001b[39;49m, engine\u001b[39m=\u001b[39;49mEMBEDDING_MODEL)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_resources/embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m         response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     35\u001b[0m         \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         \u001b[39m# This is only for the default case.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m user_provided_encoding_format:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    612\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    613\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    614\u001b[0m         )\n\u001b[1;32m    615\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    616\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 619\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    620\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    623\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    624\u001b[0m         ),\n\u001b[1;32m    625\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    626\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_requestor.py:679\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    674\u001b[0m     raise error.APIError(\n\u001b[1;32m    675\u001b[0m         f\"HTTP code {rcode} from API ({rbody})\", rbody, rcode, headers=rheaders\n\u001b[1;32m    676\u001b[0m     ) from e\n\u001b[1;32m    677\u001b[0m resp = OpenAIResponse(data, rheaders)\n\u001b[1;32m    678\u001b[0m # In the future, we might add a \"status\" parameter to errors\n\u001b[0;32m--> 679\u001b[0m # to better handle the \"error while streaming\" case.\n\u001b[1;32m    680\u001b[0m stream_error = stream and \"error\" in resp.data\n\u001b[1;32m    681\u001b[0m if stream_error or not 200 <= rcode < 300:\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: The embeddings operation does not work with the specified model, gpt-35-turbo-16k. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993."
     ]
    }
   ],
   "source": [
    "try_me  = openai.Embedding.create(input='embedd this text', engine=EMBEDDING_MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(0))\n",
    "def get_embedding(text):\n",
    "    # remove newlines and double spaces\n",
    "    text = text.replace(\"\\n\", \" \").replace(\"  \", \" \")\n",
    "    return [\"data\"][0][\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "RetryError",
     "evalue": "RetryError[<Future at 0x7feeab58cdc0 state=finished raised InvalidRequestError>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n",
      "\u001b[1;32m/workspaces/azure-openai-in-a-day-workshop/qna-quickstart-template/qna-app-quickstart.ipynb Cell 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bliterate-space-tribble-v97j7jj6q96cx9r5/workspaces/azure-openai-in-a-day-workshop/qna-quickstart-template/qna-app-quickstart.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bliterate-space-tribble-v97j7jj6q96cx9r5/workspaces/azure-openai-in-a-day-workshop/qna-quickstart-template/qna-app-quickstart.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mreturn\u001b[39;00m openai\u001b[39m.\u001b[39;49mEmbedding\u001b[39m.\u001b[39;49mcreate(\u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49mtext, engine\u001b[39m=\u001b[39;49mEMBEDDING_MODEL)[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_resources/embedding.py:33\u001b[0m, in \u001b[0;36mEmbedding.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     35\u001b[0m     \u001b[39m# If a user specifies base64, we'll just return the encoded string.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     \u001b[39m# This is only for the default case.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    138\u001b[0m (\n\u001b[1;32m    139\u001b[0m     deployment_id,\n\u001b[1;32m    140\u001b[0m     engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m     api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m )\n\u001b[0;32m--> 153\u001b[0m response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m     url,\n\u001b[1;32m    156\u001b[0m     params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m     stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m     request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m     request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m )\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    216\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m     method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m     url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m     request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m )\n\u001b[0;32m--> 226\u001b[0m resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 619\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    620\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    623\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    624\u001b[0m         ),\n\u001b[1;32m    625\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    626\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/openai/api_requestor.py:679\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    677\u001b[0m resp = OpenAIResponse(data, rheaders)\n\u001b[1;32m    678\u001b[0m # In the future, we might add a \"status\" parameter to errors\n\u001b[0;32m--> 679\u001b[0m # to better handle the \"error while streaming\" case.\n\u001b[1;32m    680\u001b[0m stream_error = stream and \"error\" in resp.data\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: The embeddings operation does not work with the specified model, gpt-35-turbo-16k. Please choose different model and try again. You can learn more about which models can be used with each operation here: https://go.microsoft.com/fwlink/?linkid=2197993.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRetryError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/azure-openai-in-a-day-workshop/qna-quickstart-template/qna-app-quickstart.ipynb Cell 9\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bliterate-space-tribble-v97j7jj6q96cx9r5/workspaces/azure-openai-in-a-day-workshop/qna-quickstart-template/qna-app-quickstart.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create embeddings for all docs\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bliterate-space-tribble-v97j7jj6q96cx9r5/workspaces/azure-openai-in-a-day-workshop/qna-quickstart-template/qna-app-quickstart.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents:\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bliterate-space-tribble-v97j7jj6q96cx9r5/workspaces/azure-openai-in-a-day-workshop/qna-quickstart-template/qna-app-quickstart.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     doc[\u001b[39m'\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m get_embedding(doc[\u001b[39m'\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bliterate-space-tribble-v97j7jj6q96cx9r5/workspaces/azure-openai-in-a-day-workshop/qna-quickstart-template/qna-app-quickstart.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCreated embedding for \u001b[39m\u001b[39m{\u001b[39;00mdoc[\u001b[39m'\u001b[39m\u001b[39mfilename\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bliterate-space-tribble-v97j7jj6q96cx9r5/workspaces/azure-openai-in-a-day-workshop/qna-quickstart-template/qna-app-quickstart.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# Save documents to disk\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/tenacity/__init__.py:326\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[1;32m    325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39mreraise()\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n\u001b[1;32m    329\u001b[0m     sleep \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait(retry_state)\n",
      "\u001b[0;31mRetryError\u001b[0m: RetryError[<Future at 0x7feeab58cdc0 state=finished raised InvalidRequestError>]"
     ]
    }
   ],
   "source": [
    "# Create embeddings for all docs\n",
    "for doc in documents:\n",
    "    doc['embedding'] = get_embedding(doc['content'])\n",
    "    print(f\"Created embedding for {doc['filename']}\")\n",
    "    \n",
    "# Save documents to disk\n",
    "pickle.dump(documents, open(\"documents.pkl\", \"wb\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, run the app:\n",
    "\n",
    "```\n",
    "streamlit run app.py\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-qna-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4ee1bbf3137c7ea9420c4fd488a55642063e5739fe2a7286130d9ba47405b69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
